{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers, models\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video_cv2(path, n_frames=1000):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    all = []\n",
    "    i = 0\n",
    "    while cap.isOpened() and i < n_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        arr = np.array(frame)\n",
    "        all.append(arr)\n",
    "        i += 1\n",
    "\n",
    "    return np.array(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Real_Life_Violence_Dataset/'\n",
    "NFileList = os.listdir(path+'NonViolence')\n",
    "VFileList = os.listdir(path+'Violence')\n",
    "\n",
    "NFileList = [x for x in NFileList if ('mp4' or 'avi') in x]\n",
    "VFileList = [x for x in VFileList if ('mp4' or 'avi') in x]\n",
    "\n",
    "FileList = NFileList + VFileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = {'NV' : 0, 'V' : 1}\n",
    "\n",
    "videos = []\n",
    "labels = []\n",
    "\n",
    "for i, file in enumerate(FileList):\n",
    "    label, _ = file.split('_') # 예시 aa_bc_01_02.jpg\n",
    "    code, ext = _.split('.') # 예시 02.jpg\n",
    "\n",
    "    if label == \"NV\":\n",
    "        code = \"NonViolence/\"\n",
    "    elif label == \"V\":\n",
    "        code = \"Violence/\"\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # 이미지 불러오기\n",
    "    video = read_video_cv2(path+code+file)\n",
    "    video.resize(video.shape[0], 32, 32, 3)\n",
    "    video = video / 255\n",
    "\n",
    "    if video.dtype != np.float64:\n",
    "        continue\n",
    "\n",
    "    if video.shape[0] < 55:\n",
    "        continue\n",
    "\n",
    "    videos.append(video[0:55])\n",
    "    labels.append(classification[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(videos)\n",
    "Y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "49/49 [==============================] - 210s 4s/step - loss: 0.7199 - accuracy: 0.5173 - val_loss: 0.6618 - val_accuracy: 0.5385\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 177s 4s/step - loss: 0.6530 - accuracy: 0.6187 - val_loss: 0.6112 - val_accuracy: 0.6538\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 163s 3s/step - loss: 0.5734 - accuracy: 0.7125 - val_loss: 0.6033 - val_accuracy: 0.6256\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 176s 4s/step - loss: 0.5618 - accuracy: 0.6977 - val_loss: 0.5711 - val_accuracy: 0.7256\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 174s 4s/step - loss: 0.5172 - accuracy: 0.7490 - val_loss: 0.5200 - val_accuracy: 0.7795\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 176s 4s/step - loss: 0.4627 - accuracy: 0.7914 - val_loss: 0.5255 - val_accuracy: 0.7692\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 175s 4s/step - loss: 0.4226 - accuracy: 0.8113 - val_loss: 0.5123 - val_accuracy: 0.7769\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 180s 4s/step - loss: 0.4020 - accuracy: 0.8158 - val_loss: 0.4287 - val_accuracy: 0.8410\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 186s 4s/step - loss: 0.3776 - accuracy: 0.8306 - val_loss: 0.5092 - val_accuracy: 0.7487\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 186s 4s/step - loss: 0.3891 - accuracy: 0.8209 - val_loss: 0.4603 - val_accuracy: 0.7795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d1b19c9c10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convolutional_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv3D(32, (3, 3, 3), activation='relu', input_shape=X_train.shape[1:]))\n",
    "    model.add(layers.MaxPooling3D((2, 2, 2)))\n",
    "    model.add(layers.Conv3D(64, (3, 3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling3D((2, 2, 2)))\n",
    "    model.add(layers.Conv3D(64, (3, 3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "model = convolutional_model()\n",
    "\n",
    "model.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SOOM\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('../model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.models.load_model('../model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 32, 32, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 55, 32, 32, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1], [1], [1]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[3][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 133ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.678309]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(X[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 55, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X[0:1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
